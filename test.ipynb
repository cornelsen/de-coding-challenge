{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = [\n",
    "    {\n",
    "        \"url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2883\",\n",
    "        \"repository_url\": \"https://api.github.com/repos/delta-io/delta-rs\",\n",
    "        \"labels_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2883/labels{/name}\",\n",
    "        \"comments_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2883/comments\",\n",
    "        \"events_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2883/events\",\n",
    "        \"html_url\": \"https://github.com/delta-io/delta-rs/pull/2883\",\n",
    "        \"id\": 2525208382,\n",
    "        \"node_id\": \"PR_kwDOD28CAs57dGWo\",\n",
    "        \"number\": 2883,\n",
    "        \"title\": \"docs: fix typo in delta-lake-dagster\",\n",
    "        \"user\": {\n",
    "            \"login\": \"jessy1092\",\n",
    "            \"id\": 4408071,\n",
    "            \"node_id\": \"MDQ6VXNlcjQ0MDgwNzE=\",\n",
    "            \"avatar_url\": \"https://avatars.githubusercontent.com/u/4408071?v=4\",\n",
    "            \"gravatar_id\": \"\",\n",
    "            \"url\": \"https://api.github.com/users/jessy1092\",\n",
    "            \"html_url\": \"https://github.com/jessy1092\",\n",
    "            \"followers_url\": \"https://api.github.com/users/jessy1092/followers\",\n",
    "            \"following_url\": \"https://api.github.com/users/jessy1092/following{/other_user}\",\n",
    "            \"gists_url\": \"https://api.github.com/users/jessy1092/gists{/gist_id}\",\n",
    "            \"starred_url\": \"https://api.github.com/users/jessy1092/starred{/owner}{/repo}\",\n",
    "            \"subscriptions_url\": \"https://api.github.com/users/jessy1092/subscriptions\",\n",
    "            \"organizations_url\": \"https://api.github.com/users/jessy1092/orgs\",\n",
    "            \"repos_url\": \"https://api.github.com/users/jessy1092/repos\",\n",
    "            \"events_url\": \"https://api.github.com/users/jessy1092/events{/privacy}\",\n",
    "            \"received_events_url\": \"https://api.github.com/users/jessy1092/received_events\",\n",
    "            \"type\": \"User\",\n",
    "            \"site_admin\": False\n",
    "        },\n",
    "        \"labels\": [],\n",
    "        \"state\": \"open\",\n",
    "        \"locked\": False,\n",
    "        \"assignee\": None,\n",
    "        \"assignees\": [],\n",
    "        \"milestone\": None,\n",
    "        \"comments\": 1,\n",
    "        \"created_at\": \"2024-09-13T16:26:35Z\",\n",
    "        \"updated_at\": \"2024-09-13T17:48:48Z\",\n",
    "        \"closed_at\": None,\n",
    "        \"author_association\": \"NONE\",\n",
    "        \"active_lock_reason\": None,\n",
    "        \"draft\": False,\n",
    "        \"pull_request\": {\n",
    "            \"url\": \"https://api.github.com/repos/delta-io/delta-rs/pulls/2883\",\n",
    "            \"html_url\": \"https://github.com/delta-io/delta-rs/pull/2883\",\n",
    "            \"diff_url\": \"https://github.com/delta-io/delta-rs/pull/2883.diff\",\n",
    "            \"patch_url\": \"https://github.com/delta-io/delta-rs/pull/2883.patch\",\n",
    "            \"merged_at\": None\n",
    "        },\n",
    "        \"body\": \"# Description\\r\\nCorrect the keyword on `Using Delta Lake and Dagster with Polars` section\\r\\n\\r\\n# Related Issue(s)\\r\\n<!---\\r\\nFor example:\\r\\n\\r\\n- closes #106\\r\\n--->\\r\\n\\r\\n# Documentation\\r\\n\\r\\n<!---\\r\\nShare links to useful documentation\\r\\n--->\\r\\n\",\n",
    "        \"closed_by\": None,\n",
    "        \"reactions\": {\n",
    "            \"url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2883/reactions\",\n",
    "            \"total_count\": 0,\n",
    "            \"+1\": 0,\n",
    "            \"-1\": 0,\n",
    "            \"laugh\": 0,\n",
    "            \"hooray\": 0,\n",
    "            \"confused\": 0,\n",
    "            \"heart\": 0,\n",
    "            \"rocket\": 0,\n",
    "            \"eyes\": 0\n",
    "        },\n",
    "        \"timeline_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2883/timeline\",\n",
    "        \"performed_via_github_app\": None,\n",
    "        \"state_reason\": None\n",
    "    },\n",
    "    {\n",
    "        \"url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2882\",\n",
    "        \"repository_url\": \"https://api.github.com/repos/delta-io/delta-rs\",\n",
    "        \"labels_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2882/labels{/name}\",\n",
    "        \"comments_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2882/comments\",\n",
    "        \"events_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2882/events\",\n",
    "        \"html_url\": \"https://github.com/delta-io/delta-rs/issues/2882\",\n",
    "        \"id\": 2524424242,\n",
    "        \"node_id\": \"I_kwDOD28CAs6Wd6gy\",\n",
    "        \"number\": 2882,\n",
    "        \"title\": \"Creating delta table with timestampNtz will create spark-incompatible delta protocol\",\n",
    "        \"user\": {\n",
    "            \"login\": \"wahani\",\n",
    "            \"id\": 3105646,\n",
    "            \"node_id\": \"MDQ6VXNlcjMxMDU2NDY=\",\n",
    "            \"avatar_url\": \"https://avatars.githubusercontent.com/u/3105646?v=4\",\n",
    "            \"gravatar_id\": \"\",\n",
    "            \"url\": \"https://api.github.com/users/wahani\",\n",
    "            \"html_url\": \"https://github.com/wahani\",\n",
    "            \"followers_url\": \"https://api.github.com/users/wahani/followers\",\n",
    "            \"following_url\": \"https://api.github.com/users/wahani/following{/other_user}\",\n",
    "            \"gists_url\": \"https://api.github.com/users/wahani/gists{/gist_id}\",\n",
    "            \"starred_url\": \"https://api.github.com/users/wahani/starred{/owner}{/repo}\",\n",
    "            \"subscriptions_url\": \"https://api.github.com/users/wahani/subscriptions\",\n",
    "            \"organizations_url\": \"https://api.github.com/users/wahani/orgs\",\n",
    "            \"repos_url\": \"https://api.github.com/users/wahani/repos\",\n",
    "            \"events_url\": \"https://api.github.com/users/wahani/events{/privacy}\",\n",
    "            \"received_events_url\": \"https://api.github.com/users/wahani/received_events\",\n",
    "            \"type\": \"User\",\n",
    "            \"site_admin\": False\n",
    "        },\n",
    "        \"labels\": [\n",
    "            {\n",
    "                \"id\": 2015286628,\n",
    "                \"node_id\": \"MDU6TGFiZWwyMDE1Mjg2NjI4\",\n",
    "                \"url\": \"https://api.github.com/repos/delta-io/delta-rs/labels/bug\",\n",
    "                \"name\": \"bug\",\n",
    "                \"color\": \"d73a4a\",\n",
    "                \"default\": True,\n",
    "                \"description\": \"Something isn't working\"\n",
    "            }\n",
    "        ],\n",
    "        \"state\": \"open\",\n",
    "        \"locked\": False,\n",
    "        \"assignee\": None,\n",
    "        \"assignees\": [],\n",
    "        \"milestone\": None,\n",
    "        \"comments\": 4,\n",
    "        \"created_at\": \"2024-09-13T09:56:49Z\",\n",
    "        \"updated_at\": \"2024-09-14T09:30:36Z\",\n",
    "        \"closed_at\": \"2024-09-14T09:30:36Z\",\n",
    "        \"author_association\": \"NONE\",\n",
    "        \"active_lock_reason\": None,\n",
    "        \"body\": \"# Environment\\r\\n\\r\\n**Delta-rs version**: python-0.16.0+ (example works until 0.15.3, also tested with 0.19.2)\\r\\n\\r\\n**Binding**: Python \\r\\n\\r\\n**Environment**:\\r\\n- **Cloud provider**:\\r\\n- **OS**: MacOS Monterey\\r\\n- **Other**: \\r\\n    - pyspark: 3.5.0\\r\\n    - pandas: 2.2.2\\r\\n    - pyarrow: 17.0.0   \\r\\n\\r\\n***\\r\\n# Bug\\r\\n\\r\\n**What happened**:\\r\\n\\r\\nBeginning with version python-0.16.0+ I receive a DeltaTableFeatureException when reading a delta table with a local spark session. This is related to the newly introduced handling of timezones. In 0.15.3 the write operation will create the following protocol `{\\\"protocol\\\":{\\\"minReaderVersion\\\":1,\\\"minWriterVersion\\\":2}}` with 0.16.0 and onward we will see `{\\\"protocol\\\":{\\\"minReaderVersion\\\":3,\\\"minWriterVersion\\\":7,\\\"readerFeatures\\\":[\\\"timestampNtz\\\"],\\\"writerFeatures\\\":[\\\"timestampNtz\\\"]}}`. However, when reading the delta table using a local spark session, I will get the following error message:\\r\\n\\r\\n```\\r\\npy4j.protocol.Py4JJavaError: An error occurred while calling o33.load.\\r\\n: org.apache.spark.sql.delta.DeltaTableFeatureException: [DELTA_FEATURES_PROTOCOL_METADATA_MISMATCH] Unable to operate on this table because the following table features are enabled in metadata but not listed in protocol: invariants.\\r\\n        at org.apache.spark.sql.delta.DeltaErrorsBase.tableFeatureMismatchException(DeltaErrors.scala:2281)\\r\\n        at org.apache.spark.sql.delta.DeltaErrorsBase.tableFeatureMismatchException$(DeltaErrors.scala:2278)\\r\\n        at org.apache.spark.sql.delta.DeltaErrors$.tableFeatureMismatchException(DeltaErrors.scala:3382)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.assertTableFeaturesMatchMetadata(DeltaLog.scala:436)\\r\\n        at org.apache.spark.sql.delta.Snapshot.init(Snapshot.scala:247)\\r\\n        at org.apache.spark.sql.delta.Snapshot.<init>(Snapshot.scala:531)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.$anonfun$createSnapshot$2(SnapshotManagement.scala:634)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment(SnapshotManagement.scala:796)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.createSnapshotFromGivenOrEquivalentLogSegment$(SnapshotManagement.scala:782)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.createSnapshotFromGivenOrEquivalentLogSegment(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.createSnapshot(SnapshotManagement.scala:627)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.createSnapshot$(SnapshotManagement.scala:618)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.createSnapshot(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotForLogSegmentInternal$1(SnapshotManagement.scala:1043)\\r\\n        at scala.Option.map(Option.scala:230)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal(SnapshotManagement.scala:1036)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.getSnapshotForLogSegmentInternal$(SnapshotManagement.scala:1031)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.getSnapshotForLogSegmentInternal(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot(SnapshotManagement.scala:1012)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.getUpdatedSnapshot$(SnapshotManagement.scala:1003)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.getUpdatedSnapshot(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$2(SnapshotManagement.scala:583)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.recordFrameProfile(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.$anonfun$getSnapshotAtInit$1(SnapshotManagement.scala:573)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly(SnapshotManagement.scala:78)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.withSnapshotLockInterruptibly$(SnapshotManagement.scala:75)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.withSnapshotLockInterruptibly(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit(SnapshotManagement.scala:573)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.getSnapshotAtInit$(SnapshotManagement.scala:572)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.getSnapshotAtInit(DeltaLog.scala:74)\\r\\n        at org.apache.spark.sql.delta.SnapshotManagement.$init$(SnapshotManagement.scala:69)\\r\\n        at org.apache.spark.sql.delta.DeltaLog.<init>(DeltaLog.scala:80)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$4(DeltaLog.scala:853)\\r\\n        at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$3(DeltaLog.scala:848)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.recordFrameProfile(DeltaLog.scala:651)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:136)\\r\\n        at com.databricks.spark.util.DatabricksLogging.recordOperation(DatabricksLogging.scala:128)\\r\\n        at com.databricks.spark.util.DatabricksLogging.recordOperation$(DatabricksLogging.scala:117)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.recordOperation(DeltaLog.scala:651)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:135)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:125)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:115)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.recordDeltaOperation(DeltaLog.scala:651)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.createDeltaLog$1(DeltaLog.scala:847)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.$anonfun$apply$5(DeltaLog.scala:866)\\r\\n        at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4792)\\r\\n        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)\\r\\n        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)\\r\\n        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)\\r\\n        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2257)\\r\\n        at com.google.common.cache.LocalCache.get(LocalCache.java:4000)\\r\\n        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4789)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.getDeltaLogFromCache$1(DeltaLog.scala:865)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.apply(DeltaLog.scala:875)\\r\\n        at org.apache.spark.sql.delta.DeltaLog$.forTable(DeltaLog.scala:751)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$deltaLog$1(DeltaTableV2.scala:92)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog$lzycompute(DeltaTableV2.scala:92)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.deltaLog(DeltaTableV2.scala:90)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$4(DeltaTableV2.scala:145)\\r\\n        at scala.Option.getOrElse(Option.scala:189)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.$anonfun$initialSnapshot$1(DeltaTableV2.scala:145)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2$.withEnrichedUnsupportedTableException(DeltaTableV2.scala:367)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot$lzycompute(DeltaTableV2.scala:144)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.initialSnapshot(DeltaTableV2.scala:124)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation$lzycompute(DeltaTableV2.scala:236)\\r\\n        at org.apache.spark.sql.delta.catalog.DeltaTableV2.toBaseRelation(DeltaTableV2.scala:234)\\r\\n        at org.apache.spark.sql.delta.sources.DeltaDataSource.$anonfun$createRelation$5(DeltaDataSource.scala:250)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:168)\\r\\n        at org.apache.spark.sql.delta.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:166)\\r\\n        at org.apache.spark.sql.delta.sources.DeltaDataSource.recordFrameProfile(DeltaDataSource.scala:49)\\r\\n        at org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:209)\\r\\n        at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\\r\\n        at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\\r\\n        at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\\r\\n        at scala.Option.getOrElse(Option.scala:189)\\r\\n        at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\\r\\n        at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\\r\\n        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\r\\n        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\r\\n        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\r\\n        at java.base/java.lang.reflect.Method.invoke(Method.java:566)\\r\\n        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\r\\n        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\\r\\n        at py4j.Gateway.invoke(Gateway.java:282)\\r\\n        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\r\\n        at py4j.commands.CallCommand.execute(CallCommand.java:79)\\r\\n        at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\\r\\n        at py4j.ClientServerConnection.run(ClientServerConnection.java:106)\\r\\n        at java.base/java.lang.Thread.run(Thread.java:829)\\r\\n```\\r\\n\\r\\nAdding 'invariants' to the writerFeatures manually will resolve the issue. So far I haven't been able to find an option to add the feature explicitly using the python bindings. E.g. by providing table configuration like \\\"delta.minReaderVersion\\\" or \\\"delta.writerFeatures\\\" - they seem to be ignored or not correct.\\r\\n\\r\\n**What you expected to happen**:\\r\\n\\r\\nI can write timestamp data with deltalake and read it back in using spark without any additional configuration (0.15.3 behavior).\\r\\n\\r\\n**How to reproduce it**:\\r\\n\\r\\n```py\\r\\nimport pyarrow as pa\\r\\nfrom deltalake import write_deltalake\\r\\nfrom pandas import DataFrame\\r\\nfrom pyspark.sql import SparkSession\\r\\n\\r\\ndelta_table_path = \\\"delta-table\\\"\\r\\n\\r\\nschema = pa.schema(\\r\\n    [\\r\\n        pa.field(\\\"id\\\", pa.int16(), False),\\r\\n        pa.field(\\\"values\\\", pa.float64(), False),\\r\\n        pa.field(\\\"date\\\", pa.timestamp(\\\"us\\\"), True),\\r\\n    ]\\r\\n)\\r\\n\\r\\nwrite_deltalake(\\r\\n    delta_table_path,\\r\\n    data=DataFrame({\\\"id\\\": [1, 2], \\\"values\\\": [2, 1], \\\"date\\\": [None, None]}),\\r\\n    schema=schema,\\r\\n    configuration={\\\"delta.minReaderVersion\\\": \\\"1\\\", \\\"delta.minWriterVersion\\\": \\\"2\\\"} # silently ignored\\r\\n)\\r\\n\\r\\nspark = (\\r\\n    SparkSession.builder.appName(\\\"failing-delta-load\\\")\\r\\n    .config(\\\"spark.sql.extensions\\\", \\\"io.delta.sql.DeltaSparkSessionExtension\\\")\\r\\n    .config(\\\"spark.sql.catalog.spark_catalog\\\", \\\"org.apache.spark.sql.delta.catalog.DeltaCatalog\\\")\\r\\n    .config(\\\"spark.jars\\\", \\\"delta-spark_2.12-3.2.0.jar,delta-storage-3.2.0.jar\\\")\\r\\n    .getOrCreate()\\r\\n)\\r\\n\\r\\ndf = spark.read.format(\\\"delta\\\").load(delta_table_path)\\r\\n\\r\\nfor row in df.collect():\\r\\n    print(row)\\r\\n\\r\\n```\\r\\n\\r\\nThanks for any help or guidance with this.\\r\\n\",\n",
    "        \"closed_by\": None,\n",
    "        \"reactions\": {\n",
    "            \"url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2882/reactions\",\n",
    "            \"total_count\": 0,\n",
    "            \"+1\": 0,\n",
    "            \"-1\": 0,\n",
    "            \"laugh\": 0,\n",
    "            \"hooray\": 0,\n",
    "            \"confused\": 0,\n",
    "            \"heart\": 0,\n",
    "            \"rocket\": 0,\n",
    "            \"eyes\": 0\n",
    "        },\n",
    "        \"timeline_url\": \"https://api.github.com/repos/delta-io/delta-rs/issues/2882/timeline\",\n",
    "        \"performed_via_github_app\": None,\n",
    "        \"state_reason\": None\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['closed_at'] = pd.to_datetime(df['closed_at'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pull_request' in df.columns:\n",
    "    df_prs = df[df.pull_request.notna()]\n",
    "    df_issues = df[df.pull_request.isna()]\n",
    "else:\n",
    "    df_prs = df.iloc[[]] # no PRs, empty dataframe\n",
    "    df_issues = df # no PRs, all rows are issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df_issues.closed_at - df_issues.created_at).dt.total_seconds() / 86400).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value must be Timedelta, string, integer, float, timedelta or convertible, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_issues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosed_at\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_issues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdays\n",
      "File \u001b[0;32mtimedeltas.pyx:1900\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timedeltas.Timedelta.__new__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Value must be Timedelta, string, integer, float, timedelta or convertible, not Series"
     ]
    }
   ],
   "source": [
    "pd.Timedelta((df_issues.closed_at - df_issues.created_at)).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert from timedelta64[ns] to timedelta64[h]. Supported resolutions are 's', 'ms', 'us', 'ns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m(\u001b[49m\u001b[43mdf_issues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosed_at\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf_issues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreated_at\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimedelta64[h]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:179\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arrays/timedeltas.py:358\u001b[0m, in \u001b[0;36mTimedeltaArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(\n\u001b[1;32m    355\u001b[0m             res_values, dtype\u001b[38;5;241m=\u001b[39mres_values\u001b[38;5;241m.\u001b[39mdtype, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq\n\u001b[1;32m    356\u001b[0m         )\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    359\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported resolutions are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m         )\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtl\u001b[38;5;241m.\u001b[39mDatetimeLikeArrayMixin\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert from timedelta64[ns] to timedelta64[h]. Supported resolutions are 's', 'ms', 'us', 'ns'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "(df_issues.closed_at - df_issues.created_at).astype('timedelta64[h]'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "for df in [df_prs, df_issues]:\n",
    "    df = df[df.closed_at.notna()]\n",
    "    df['duration'] = ((df.closed_at - df.created_at).dt.total_seconds() / 86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df.duration.mean(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>draft</th>\n",
       "      <th>pull_request</th>\n",
       "      <th>body</th>\n",
       "      <th>closed_by</th>\n",
       "      <th>reactions</th>\n",
       "      <th>timeline_url</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>state_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://github.com/delta-io/delta-rs/issues/2882</td>\n",
       "      <td>2524424242</td>\n",
       "      <td>I_kwDOD28CAs6Wd6gy</td>\n",
       "      <td>2882</td>\n",
       "      <td>Creating delta table with timestampNtz will cr...</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td># Environment\\r\\n\\r\\n**Delta-rs version**: pyt...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/delta-io...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                   repository_url  \\\n",
       "1  https://api.github.com/repos/delta-io/delta-rs   \n",
       "\n",
       "                                          labels_url  \\\n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                          events_url  \\\n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                           html_url          id  \\\n",
       "1  https://github.com/delta-io/delta-rs/issues/2882  2524424242   \n",
       "\n",
       "              node_id  number  \\\n",
       "1  I_kwDOD28CAs6Wd6gy    2882   \n",
       "\n",
       "                                               title  ... author_association  \\\n",
       "1  Creating delta table with timestampNtz will cr...  ...               NONE   \n",
       "\n",
       "  active_lock_reason draft  pull_request  \\\n",
       "1               None   NaN           NaN   \n",
       "\n",
       "                                                body closed_by  \\\n",
       "1  # Environment\\r\\n\\r\\n**Delta-rs version**: pyt...      None   \n",
       "\n",
       "                                           reactions  \\\n",
       "1  {'url': 'https://api.github.com/repos/delta-io...   \n",
       "\n",
       "                                        timeline_url performed_via_github_app  \\\n",
       "1  https://api.github.com/repos/delta-io/delta-rs...                     None   \n",
       "\n",
       "  state_reason  \n",
       "1         None  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>draft</th>\n",
       "      <th>pull_request</th>\n",
       "      <th>body</th>\n",
       "      <th>closed_by</th>\n",
       "      <th>reactions</th>\n",
       "      <th>timeline_url</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>state_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://github.com/delta-io/delta-rs/pull/2883</td>\n",
       "      <td>2525208382</td>\n",
       "      <td>PR_kwDOD28CAs57dGWo</td>\n",
       "      <td>2883</td>\n",
       "      <td>docs: fix typo in delta-lake-dagster</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/delta-io...</td>\n",
       "      <td># Description\\r\\nCorrect the keyword on `Using...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/delta-io...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>https://github.com/delta-io/delta-rs/issues/2882</td>\n",
       "      <td>2524424242</td>\n",
       "      <td>I_kwDOD28CAs6Wd6gy</td>\n",
       "      <td>2882</td>\n",
       "      <td>Creating delta table with timestampNtz will cr...</td>\n",
       "      <td>...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td># Environment\\r\\n\\r\\n**Delta-rs version**: pyt...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/delta-io...</td>\n",
       "      <td>https://api.github.com/repos/delta-io/delta-rs...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                   repository_url  \\\n",
       "0  https://api.github.com/repos/delta-io/delta-rs   \n",
       "1  https://api.github.com/repos/delta-io/delta-rs   \n",
       "\n",
       "                                          labels_url  \\\n",
       "0  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "0  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                          events_url  \\\n",
       "0  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "1  https://api.github.com/repos/delta-io/delta-rs...   \n",
       "\n",
       "                                           html_url          id  \\\n",
       "0    https://github.com/delta-io/delta-rs/pull/2883  2525208382   \n",
       "1  https://github.com/delta-io/delta-rs/issues/2882  2524424242   \n",
       "\n",
       "               node_id  number  \\\n",
       "0  PR_kwDOD28CAs57dGWo    2883   \n",
       "1   I_kwDOD28CAs6Wd6gy    2882   \n",
       "\n",
       "                                               title  ... author_association  \\\n",
       "0               docs: fix typo in delta-lake-dagster  ...               NONE   \n",
       "1  Creating delta table with timestampNtz will cr...  ...               NONE   \n",
       "\n",
       "  active_lock_reason  draft  \\\n",
       "0               None  False   \n",
       "1               None    NaN   \n",
       "\n",
       "                                        pull_request  \\\n",
       "0  {'url': 'https://api.github.com/repos/delta-io...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                                body closed_by  \\\n",
       "0  # Description\\r\\nCorrect the keyword on `Using...      None   \n",
       "1  # Environment\\r\\n\\r\\n**Delta-rs version**: pyt...      None   \n",
       "\n",
       "                                           reactions  \\\n",
       "0  {'url': 'https://api.github.com/repos/delta-io...   \n",
       "1  {'url': 'https://api.github.com/repos/delta-io...   \n",
       "\n",
       "                                        timeline_url performed_via_github_app  \\\n",
       "0  https://api.github.com/repos/delta-io/delta-rs...                     None   \n",
       "1  https://api.github.com/repos/delta-io/delta-rs...                     None   \n",
       "\n",
       "  state_reason  \n",
       "0         None  \n",
       "1         None  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>draft</th>\n",
       "      <th>pull_request</th>\n",
       "      <th>body</th>\n",
       "      <th>closed_by</th>\n",
       "      <th>reactions</th>\n",
       "      <th>timeline_url</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>state_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url, repository_url, labels_url, comments_url, events_url, html_url, id, node_id, number, title, user, labels, state, locked, assignee, assignees, milestone, comments, created_at, updated_at, closed_at, author_association, active_lock_reason, draft, pull_request, body, closed_by, reactions, timeline_url, performed_via_github_app, state_reason]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "Name: pull_request, dtype: bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pull_request.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "Name: closed_at, dtype: bool"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.closed_at.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   NaT\n",
       "1   NaT\n",
       "Name: closed_at, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['closed_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot subtract tz-naive and tz-aware datetime-like objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:1165\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._sub_datetimelike\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_tzawareness_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:782\u001b[0m, in \u001b[0;36mDatetimeArray._assert_tzawareness_compat\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 782\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    783\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compare tz-naive and tz-aware datetime-like objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m         )\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m other_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare tz-naive and tz-aware datetime-like objects.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclosed_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:1459\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1454\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_addsub_object_array(other, operator\u001b[38;5;241m.\u001b[39msub)\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(other_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1456\u001b[0m     other_dtype, DatetimeTZDtype\n\u001b[1;32m   1457\u001b[0m ):\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;66;03m# DatetimeIndex, ndarray[datetime64]\u001b[39;00m\n\u001b[0;32m-> 1459\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sub_datetime_arraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other_dtype, PeriodDtype):\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;66;03m# PeriodIndex\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sub_periodlike(other)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:1156\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._sub_datetime_arraylike\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatetimeArray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_matching_resos(other)\n\u001b[0;32m-> 1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sub_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/github-pipeline-bQjmFwtI-py3.10/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:1168\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._sub_datetimelike\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1167\u001b[0m     new_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompare\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtract\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(new_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m other_i8, o_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_i8_values_and_mask(other)\n\u001b[1;32m   1171\u001b[0m res_values \u001b[38;5;241m=\u001b[39m add_overflowsafe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masi8, np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;241m-\u001b[39mother_i8, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot subtract tz-naive and tz-aware datetime-like objects."
     ]
    }
   ],
   "source": [
    "df['closed_at']-df['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'repository_url', 'labels_url', 'comments_url', 'events_url',\n",
       "       'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels',\n",
       "       'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments',\n",
       "       'created_at', 'updated_at', 'closed_at', 'author_association',\n",
       "       'active_lock_reason', 'draft', 'pull_request', 'body', 'closed_by',\n",
       "       'reactions', 'timeline_url', 'performed_via_github_app',\n",
       "       'state_reason'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contributions\n",
       "1      97\n",
       "2      23\n",
       "3      15\n",
       "4       6\n",
       "17      5\n",
       "5       5\n",
       "10      2\n",
       "20      2\n",
       "11      2\n",
       "9       2\n",
       "6       2\n",
       "8       2\n",
       "274     1\n",
       "24      1\n",
       "27      1\n",
       "39      1\n",
       "40      1\n",
       "43      1\n",
       "48      1\n",
       "54      1\n",
       "90      1\n",
       "98      1\n",
       "110     1\n",
       "170     1\n",
       "178     1\n",
       "12      1\n",
       "14      1\n",
       "16      1\n",
       "7       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.contributions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {\n",
    "    'delta-rs': {\n",
    "        'stars': 11,\n",
    "        'forks': 5,\n",
    "    },\n",
    "    'hudi-rs': {\n",
    "        'stars': 4,\n",
    "        'forks': 2,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_table = df.to_markdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github-pipeline-bQjmFwtI-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
